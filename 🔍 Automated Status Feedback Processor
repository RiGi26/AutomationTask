import pandas as pd
import numpy as np
from pathlib import Path
import os
import logging
from typing import Dict, List, Optional, Tuple, Union, Any
from dataclasses import dataclass
from datetime import datetime
import re
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter


@dataclass
class StatusProcessorConfig:
    """Configuration class for MOXA Status Feedback processing"""
    # Date and folder configuration
    folder_year: str = "2025"
    folder_month: str = "Mei"
    first_date: str = '2025-05-01'
    second_date: str = '2025-05-25'
    output_filename: str = 'MOXA STATUS FEEDBACK 20250525.xlsx'

    # File paths
    data_raw_moxa: Path = Path("D:\\Daily MOXA\\Data Leads MOXA.xlsx")
    data_raw_dealer: Path = Path("D:\\Daily MOXA\\Leads FIFGROUP Compile all MD v2.xlsx")
    data_dl: Path = Path(r"D:\Report DL UFI\Mei\26\RPT_DIGITAL_LEADS_HO_2025.xls.xlsx")
    file_refi: Path = Path(r"C:\Users\61140\Downloads\exportDanastra (14).xlsx")
    file_amitra: Path = Path(r"C:\Users\61140\Downloads\Export AMITRA (3).xlsx")

    # Processing configuration
    call_columns: List[str] = None
    lobs: List[str] = None
    digit_columns: List[str] = None

    # Excel formatting configuration
    autofit_enabled: bool = True
    min_column_width: int = 8
    max_column_width: int = 50
    column_padding: int = 2

    def __post_init__(self):
        """Initialize default values if not provided"""
        if self.call_columns is None:
            self.call_columns = ['hasil call 1', 'hasil call 1.1', 'hasil call 1.2']

        if self.lobs is None:
            self.lobs = ['NMC', 'NMC SY']

        if self.digit_columns is None:
            self.digit_columns = ['Phone', 'Phone (Optional)', 'Nomor KTP', 'Id Leads Data User', 'Id User Profile']

    @property
    def base_path(self) -> Path:
        """Get the base output path"""
        return Path(f"D:\\etc\\Cross Selling\\Moxa\\Booking\\{self.folder_year}\\{self.folder_month}")

    @property
    def output_path(self) -> Path:
        """Get the full output file path"""
        return self.base_path / self.output_filename


class ExcelFormatter:
    """Handles Excel formatting operations"""

    def __init__(self, min_width: int = 8, max_width: int = 50, padding: int = 2):
        self.min_width = min_width
        self.max_width = max_width
        self.padding = padding

    def autofit_columns(self, worksheet) -> None:
        """Adjust column widths automatically based on content"""
        for column in worksheet.columns:
            max_length = self._get_max_column_length(column)
            column_letter = get_column_letter(column[0].column)
            adjusted_width = self._calculate_width(max_length)
            worksheet.column_dimensions[column_letter].width = adjusted_width

    def _get_max_column_length(self, column) -> int:
        """Get maximum text length in a column"""
        max_length = 0
        for cell in column:
            try:
                if cell.value is not None:
                    cell_length = len(str(cell.value))
                    if cell_length > max_length:
                        max_length = cell_length
            except Exception:
                continue
        return max_length

    def _calculate_width(self, length: int) -> int:
        """Calculate adjusted width with bounds checking"""
        adjusted_width = length + self.padding
        return max(self.min_width, min(adjusted_width, self.max_width))


class NumericValidator:
    """
    Kelas untuk validasi dan penanganan data numerik panjang
    yang sering bermasalah di Excel
    """

    def __init__(self):
        self.validation_results = []

    def validate_long_number(self, value: Union[str, int, float]) -> Dict[str, Any]:
        """
        Validasi angka panjang dan deteksi masalah format

        Args:
            value: Nilai yang akan divalidasi

        Returns:
            Dict dengan informasi validasi
        """
        result = {
            'original_value': value,
            'value_type': type(value).__name__,
            'is_valid': True,
            'issues': [],
            'corrected_value': None,
            'suggestions': []
        }

        # Skip jika nilai kosong atau NaN
        if pd.isna(value) or value == '' or value == 'nan':
            return result

        # Konversi ke string untuk analisis
        str_value = str(value)

        # Cek apakah ada decimal point yang tidak seharusnya
        if str_value.endswith('.0'):
            result['issues'].append('Decimal point tidak diperlukan')
            result['corrected_value'] = str_value.replace('.0', '')
            result['suggestions'].append('Hapus .0 di akhir')

        # Cek panjang angka
        clean_number = str_value.replace('.0', '').replace('.', '')
        if len(clean_number) > 15:
            result['issues'].append(f'Angka terlalu panjang ({len(clean_number)} digit)')
            result['suggestions'].append('Simpan sebagai text untuk mencegah kehilangan presisi')

        # Cek apakah mirip dengan format tertentu
        if len(clean_number) == 16:
            result['suggestions'].append('Kemungkinan NIK - format sebagai text')
        elif len(clean_number) >= 10 and len(clean_number) <= 15:
            result['suggestions'].append('Kemungkinan nomor telepon/rekening - format sebagai text')

        # Cek scientific notation
        if 'e' in str_value.lower() or '+' in str_value:
            result['issues'].append('Dalam format scientific notation')
            result['suggestions'].append('Konversi kembali ke format normal')

        if result['issues']:
            result['is_valid'] = False

        return result

    def fix_excel_number_format(self, value: Union[str, int, float]) -> str:
        """
        Perbaiki format angka yang rusak dari Excel

        Args:
            value: Nilai yang akan diperbaiki

        Returns:
            String nilai yang sudah diperbaiki
        """
        if pd.isna(value) or value == '' or value == 'nan':
            return ''

        str_value = str(value)

        # Hapus .0 di akhir jika ada
        if str_value.endswith('.0'):
            str_value = str_value[:-2]

        # Konversi scientific notation ke normal
        if 'e' in str_value.lower():
            try:
                # Konversi ke float lalu ke int untuk menghilangkan scientific notation
                float_val = float(str_value)
                if float_val.is_integer():
                    str_value = str(int(float_val))
                else:
                    str_value = str(float_val)
            except ValueError:
                pass

        return str_value

    def validate_dataframe_column(self, df: pd.DataFrame, column_name: str) -> Dict[str, Any]:
        """
        Validasi seluruh kolom dalam DataFrame

        Args:
            df: DataFrame pandas
            column_name: Nama kolom yang akan divalidasi

        Returns:
            Dict dengan ringkasan validasi kolom
        """
        if column_name not in df.columns:
            return {'error': f'Kolom {column_name} tidak ditemukan'}

        column_data = df[column_name]
        results = {
            'column_name': column_name,
            'total_rows': len(column_data),
            'issues_found': 0,
            'detailed_results': [],
            'summary': {
                'decimal_issues': 0,
                'too_long': 0,
                'scientific_notation': 0
            }
        }

        for idx, value in enumerate(column_data):
            if pd.isna(value):
                continue

            validation = self.validate_long_number(value)
            if not validation['is_valid']:
                results['issues_found'] += 1
                validation['row_index'] = idx
                results['detailed_results'].append(validation)

                # Update summary
                for issue in validation['issues']:
                    if 'Decimal point' in issue:
                        results['summary']['decimal_issues'] += 1
                    elif 'terlalu panjang' in issue:
                        results['summary']['too_long'] += 1
                    elif 'scientific notation' in issue:
                        results['summary']['scientific_notation'] += 1

        return results


class MOXAStatusProcessor:
    """Enhanced MOXA Status Feedback Processor with Excel Formatting"""

    def __init__(self, config: Optional[StatusProcessorConfig] = None):
        self.config = config or StatusProcessorConfig()
        self.logger = self._setup_logging()

        # Initialize validators and formatters
        self.numeric_validator = NumericValidator()
        self.excel_formatter = ExcelFormatter(
            min_width=self.config.min_column_width,
            max_width=self.config.max_column_width,
            padding=self.config.column_padding
        )

        # Column mappings (unchanged from original)
        self.refi_column_mapping = {
            "Lead ID": "Id User Profile",
            "Digital Lead Id": "Id Leads Data User",
            "Fullname": "Name",
            "Mobile Phone1": "Phone",
            "No KTP": "Nomor KTP",
            "Submit Date": "Transaction"
        }

        self.amitra_column_mapping = {
            "Lead ID": "Id User Profile",
            "Digital Lead Id": "Id Leads Data User",
            "Nama Lengkap": "Name",
            "Nomor HP": "Phone",
            "Nomor KTP": "Nomor KTP",
            "Submit Date": "Transaction"
        }

        self.status_mapping = {
            "NOT ANSWERED": "Unreachable",
            "NOT INTERESTED": "Canceled",
            "INPROGRESS": "In Progress",
            "INTERESTED": "In Progress"
        }

        self.detail_status_mapping = {
            'CUSTOMER HANYA COBA-COBA': 'Canceled',
            'INTEREST': 'In Progress',
            'NO ANSWER': 'Unreachable',
            'LINE BUSY': 'Unreachable',
            'NOT ACTIVE': 'Unreachable',
            'CALL AGAIN, DIHUBUNGI KEMBALI': 'Unreachable',
            'CNC, TERHUBUNG DENGAN KELUARGA YBS': 'Unreachable'
        }

        self.detail_replacements = {
            'CUTSTOMER HANYA COBA-COBA': 'CUSTOMER HANYA COBA-COBA',
            'INTERST': 'INTEREST',
            'INTERETS': 'INTEREST',
            'INTREST': 'INTEREST',
            'CNC, TERHUBUNG\xa0DENGAN ADIK YBS': 'CNC, TERHUBUNG DENGAN KELUARGA YBS',
            'NO  ANSWER': 'NO ANSWER'
        }

        self._validate_configuration()

    def _setup_logging(self) -> logging.Logger:
        """Setup logging configuration"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)

    def _validate_configuration(self) -> None:
        """Validate configuration and create necessary directories"""
        try:
            # Create output directory
            os.makedirs(self.config.base_path, exist_ok=True)
            self.logger.info(f"Output directory ready: {self.config.base_path}")

            # Validate required files exist
            required_files = [
                self.config.data_raw_moxa,
                self.config.data_raw_dealer,
                self.config.data_dl
            ]

            for file_path in required_files:
                if not file_path.exists():
                    self.logger.warning(f"Required file not found: {file_path}")

            # Set pandas options
            pd.set_option('display.max_columns', None)
            pd.set_option('display.width', 2000)

        except Exception as e:
            self.logger.error(f"Configuration validation failed: {e}")
            raise

    def set_excel_formatting_params(self, min_width: int = None, max_width: int = None,
                                    padding: int = None) -> 'MOXAStatusProcessor':
        """Update Excel formatting parameters"""
        if min_width is not None:
            self.excel_formatter.min_width = min_width
        if max_width is not None:
            self.excel_formatter.max_width = max_width
        if padding is not None:
            self.excel_formatter.padding = padding
        return self

    # [Previous methods remain the same until export_to_excel]
    # ... (load_and_process_dealer_data, standardize_phone_and_ktp, etc.)

    def load_and_process_dealer_data(self) -> pd.DataFrame:
        """Load and process dealer data"""
        try:
            self.logger.info("Loading dealer data...")
            df_dealer = pd.read_excel(self.config.data_raw_dealer)

            # Validate numeric columns
            if 'Id Leads Data User' in df_dealer.columns:
                self.logger.info("Validating Id Leads Data User in dealer data...")
                validation_result = self.numeric_validator.validate_dataframe_column(
                    df_dealer, 'Id Leads Data User'
                )
                if validation_result['issues_found'] > 0:
                    self.logger.warning(
                        f"Found {validation_result['issues_found']} numeric issues in dealer Id Leads Data User")
                    df_dealer['Id Leads Data User'] = df_dealer['Id Leads Data User'].apply(
                        self.numeric_validator.fix_excel_number_format
                    )

            # Process Group Status for Blacklist
            df_dealer['Group Status'] = df_dealer.apply(
                lambda row: f"{row['Group Status']}, blacklist"
                if pd.isna(row['Dispatch Date'])
                else row['Group Status'],
                axis=1
            )

            df_dealer['Group Status'] = df_dealer['Group Status'].fillna('Belum ada feedback')

            # Concatenate Dealer Status
            df_dealer['Dealer Status'] = df_dealer[
                ['Group Status', 'Progress FU', 'Prospect Pending']
            ].fillna('').agg(' '.join, axis=1)

            df_dealer = df_dealer[['Id Leads Data User', 'Dealer Status']]

            self.logger.info(f"Dealer data processed: {len(df_dealer)} records")
            return df_dealer

        except Exception as e:
            self.logger.error(f"Failed to process dealer data: {e}")
            raise

    def standardize_phone_and_ktp(self, df: pd.DataFrame) -> pd.DataFrame:
        """Standardize phone numbers and KTP"""
        try:
            for col in ['Phone', 'Nomor KTP']:
                if col in df.columns:
                    # Validate numeric format
                    self.logger.info(f"Validating numeric format for {col}...")
                    validation_result = self.numeric_validator.validate_dataframe_column(df, col)

                    if validation_result['issues_found'] > 0:
                        self.logger.warning(f"Found {validation_result['issues_found']} format issues in {col}")
                        df[col] = df[col].apply(self.numeric_validator.fix_excel_number_format)

                    # Convert to string
                    df[col] = df[col].astype(str)
                    self.logger.info(f"Converted {col} to string type")

            # Handle KTP
            if 'Nomor KTP' in df.columns:
                df['Nomor KTP'] = df['Nomor KTP'].apply(lambda x: x if x and x != 'nan' else "")

            # Handle Phone
            if 'Phone' in df.columns:
                df['Phone'] = df['Phone'].apply(
                    lambda x: "0" + x if x and x != 'nan' and not x.startswith("0") else x
                )

            return df

        except Exception as e:
            self.logger.error(f"Phone/KTP standardization failed: {e}")
            raise

    def clean_call_results(self, df: pd.DataFrame) -> pd.DataFrame:
        """Clean and process call results"""
        try:
            df_cleaned = df.copy()

            # Convert to uppercase
            df_cleaned[self.config.call_columns] = df_cleaned[self.config.call_columns].apply(
                lambda x: x.str.upper() if x.dtype == 'object' else x
            )

            # Remove (DOUBLE) pattern
            for col in self.config.call_columns:
                if col in df_cleaned.columns:
                    df_cleaned[col] = df_cleaned[col].str.replace(r'\(DOUBLE\)', '', regex=True).str.strip()

            # Apply cascading logic
            if all(col in df_cleaned.columns for col in ['hasil call 1.2', 'hasil call 1.1', 'hasil call 1']):
                df_cleaned.loc[df_cleaned['hasil call 1.2'].notna(), 'hasil call 1.1'] = df_cleaned['hasil call 1.2']
                df_cleaned.loc[df_cleaned['hasil call 1.1'].notna(), 'hasil call 1'] = df_cleaned['hasil call 1.1']
                df_cleaned.loc[df_cleaned['hasil call 1'].notna(), 'Detail'] = df_cleaned['hasil call 1']

            return df_cleaned

        except Exception as e:
            self.logger.error(f"Call results cleaning failed: {e}")
            raise

    def standardize_detail_and_status(self, df: pd.DataFrame) -> pd.DataFrame:
        """Standardize detail text and map status"""
        try:
            if 'Detail' in df.columns:
                df['Detail'] = df['Detail'].replace(self.detail_replacements, regex=True)
                df['Status'] = df['Detail'].map(self.detail_status_mapping).fillna(df.get('Status', ''))
                df['Detail'] = df['Detail'].apply(lambda x: x.title() if isinstance(x, str) else x)

            return df

        except Exception as e:
            self.logger.error(f"Detail/Status standardization failed: {e}")
            raise

    def process_lob_data(self, lob: str, df_dealer: pd.DataFrame) -> pd.DataFrame:
        """Process data for a specific LOB"""
        try:
            self.logger.info(f"Processing LOB: {lob}")

            df = pd.read_excel(self.config.data_raw_moxa, sheet_name=lob)

            # Validate numeric columns
            self.logger.info(f"Validating numeric columns for LOB {lob}...")
            for col in self.config.digit_columns:
                if col in df.columns:
                    validation_result = self.numeric_validator.validate_dataframe_column(df, col)
                    if validation_result['issues_found'] > 0:
                        self.logger.warning(f"Found {validation_result['issues_found']} issues in {col} for LOB {lob}")
                        df[col] = df[col].apply(self.numeric_validator.fix_excel_number_format)

            df['Transaction'] = pd.to_datetime(df['Transaction'], errors='coerce')
            df = df[
                (df['Transaction'] >= self.config.first_date) &
                (df['Transaction'] < self.config.second_date)
                ]

            df = self.standardize_phone_and_ktp(df)
            df = self.clean_call_results(df)
            df = self.standardize_detail_and_status(df)

            # Drop unnecessary columns
            cols_to_drop = [
                'kelurahan', 'dihubungi', 'melalui media', 'tanggal penarikan',
                'tanggal call 1', 'hasil call 1', 'tanggal call 2', 'hasil call 1.1',
                'tanggal call 3', 'hasil call 1.2'
            ]
            df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])

            df = df.merge(df_dealer, on='Id Leads Data User', how='left')
            df['LOB'] = lob

            self.logger.info(f"LOB {lob} processed: {len(df)} records")
            return df

        except Exception as e:
            self.logger.error(f"Failed to process LOB {lob}: {e}")
            raise

    def process_external_data(self, file_path: Path, column_mapping: Dict[str, str],
                              lob_name: str) -> Optional[pd.DataFrame]:
        """Process external data files (REFI/AMITRA)"""
        try:
            if not file_path.exists():
                self.logger.warning(f"{lob_name} file not found: {file_path}")
                return None

            self.logger.info(f"Processing {lob_name} data...")

            df = pd.read_excel(file_path)

            # Validate numeric columns before mapping
            numeric_cols_to_check = ['Lead ID', 'Digital Lead Id', 'Mobile Phone1', 'Nomor HP', 'No KTP', 'Nomor KTP']
            for col in numeric_cols_to_check:
                if col in df.columns:
                    validation_result = self.numeric_validator.validate_dataframe_column(df, col)
                    if validation_result['issues_found'] > 0:
                        self.logger.warning(f"Found {validation_result['issues_found']} issues in {col} for {lob_name}")
                        df[col] = df[col].apply(self.numeric_validator.fix_excel_number_format)

            df = df[list(column_mapping.keys())].rename(columns=column_mapping)

            if "Transaction" in df.columns:
                df["Transaction"] = pd.to_datetime(df["Transaction"], errors="coerce")

            df = self.standardize_phone_and_ktp(df)
            df = df.drop_duplicates(subset=["Id Leads Data User", "Phone", "Nomor KTP"])

            # Load DL data and merge
            df_dl = pd.read_excel(self.config.data_dl)

            if 'Lead ID' in df_dl.columns:
                validation_result = self.numeric_validator.validate_dataframe_column(df_dl, 'Lead ID')
                if validation_result['issues_found'] > 0:
                    self.logger.warning(f"Found {validation_result['issues_found']} issues in DL Lead ID")
                    df_dl['Lead ID'] = df_dl['Lead ID'].apply(self.numeric_validator.fix_excel_number_format)

            df_merged = pd.merge(df_dl, df, left_on='Lead ID', right_on='Id User Profile')

            # Select and process required columns
            required_cols = [
                'Id User Profile', 'Id Leads Data User', 'Name', 'Phone', 'Nomor KTP',
                'Transaction', 'Status E-Form Customer', 'Status FM Connect / FM Sales'
            ]
            df_final = df_merged[required_cols].copy()

            df_final['Status'] = ''
            df_final['Detail'] = df_final['Status FM Connect / FM Sales']
            df_final['Status E-Form Customer'] = df_final['Status E-Form Customer'].fillna('INPROGRESS')
            df_final['Status'] = df_final['Status E-Form Customer'].map(self.status_mapping)

            # Apply complex status logic
            df_final['Status'] = df_final.apply(
                lambda row: 'Canceled'
                if row['Status E-Form Customer'] == 'INTERESTED' and
                   row['Status FM Connect / FM Sales'] == 'NOT INTEREST'
                else row['Status'],
                axis=1
            )

            df_final = df_final.drop(columns='Status FM Connect / FM Sales')
            df_final['LOB'] = lob_name

            self.logger.info(f"{lob_name} data processed: {len(df_final)} records")
            return df_final

        except Exception as e:
            self.logger.error(f"Failed to process {lob_name} data: {e}")
            return None

    def export_to_excel(self, data_sheets: Dict[str, pd.DataFrame],
                        autofit: bool = None, engine: str = 'xlsxwriter') -> None:
        """
        Enhanced export method with autofit capability

        Args:
            data_sheets: Dictionary of sheet names and DataFrames
            autofit: Whether to apply autofit (uses config default if None)
            engine: Excel engine to use
        """
        try:
            if autofit is None:
                autofit = self.config.autofit_enabled

            self.logger.info(f"Exporting data to {self.config.output_path}")

            # Export data using pandas
            with pd.ExcelWriter(self.config.output_path, engine=engine) as writer:
                for sheet_name, df in data_sheets.items():
                    if df is not None and not df.empty:
                        # Final validation before export
                        processed_df = self._preprocess_dataframe_for_export(df.copy())
                        processed_df.to_excel(writer, sheet_name=sheet_name, index=False)
                        self.logger.info(f"Exported {sheet_name}: {len(processed_df)} records")
                    else:
                        self.logger.warning(f"Skipped empty sheet: {sheet_name}")

            # Apply formatting if requested
            if autofit:
                self._apply_excel_formatting()

            self.logger.info(f"Export completed successfully: {self.config.output_path}")

        except Exception as e:
            self.logger.error(f"Export failed: {e}")
            raise

    def _preprocess_dataframe_for_export(self, df: pd.DataFrame) -> pd.DataFrame:
        """Preprocess DataFrame before export"""
        # Final numeric validation
        for col in self.config.digit_columns:
            if col in df.columns:
                df[col] = df[col].apply(self.numeric_validator.fix_excel_number_format)

        return df

    def _apply_excel_formatting(self) -> None:
        """Apply Excel formatting using openpyxl"""
        try:
            self.logger.info("Applying Excel formatting...")

            # Load workbook with openpyxl for formatting
            workbook = load_workbook(self.config.output_path)

            for sheet_name in workbook.sheetnames:
                worksheet = workbook[sheet_name]
                self.excel_formatter.autofit_columns(worksheet)
                self.logger.debug(f"Applied autofit to sheet: {sheet_name}")

            # Save formatted workbook
            workbook.save(self.config.output_path)
            self.logger.info("Excel formatting applied successfully")

        except Exception as e:
            self.logger.warning(f"Failed to apply Excel formatting: {e}")
            # Don't raise - data export was successful, formatting is optional

    def validate_processed_data(self, data_sheets: Dict[str, pd.DataFrame]) -> None:
        """Validate processed data quality"""
        try:
            total_records = 0
            total_numeric_issues = 0

            for sheet_name, df in data_sheets.items():
                if df is not None:
                    total_records += len(df)

                    # Check for required columns
                    required_cols = ['Id User Profile', 'Id Leads Data User']
                    missing_cols = [col for col in required_cols if col not in df.columns]
                    if missing_cols:
                        self.logger.warning(f"Missing columns in {sheet_name}: {missing_cols}")

                    # Validate numeric columns per sheet
                    sheet_numeric_issues = 0
                    for col in self.config.digit_columns:
                        if col in df.columns:
                            validation_result = self.numeric_validator.validate_dataframe_column(df, col)
                            if validation_result['issues_found'] > 0:
                                sheet_numeric_issues += validation_result['issues_found']
                                self.logger.warning(
                                    f"Sheet {sheet_name}, Column {col}: {validation_result['issues_found']} numeric issues")

                    total_numeric_issues += sheet_numeric_issues
                    if sheet_numeric_issues > 0:
                        self.logger.warning(f"Total numeric issues in {sheet_name}: {sheet_numeric_issues}")

                    # Check data quality
                    null_percentages = df.isnull().sum() / len(df) * 100
                    high_null_cols = null_percentages[null_percentages > 50]
                    if not high_null_cols.empty:
                        self.logger.warning(f"High null percentages in {sheet_name}: {high_null_cols.to_dict()}")

            self.logger.info(f"Data validation completed. Total records: {total_records}")
            if total_numeric_issues > 0:
                self.logger.warning(f"Total numeric format issues found and fixed: {total_numeric_issues}")
            else:
                self.logger.info("No numeric format issues detected")

        except Exception as e:
            self.logger.error(f"Data validation failed: {e}")

    def process_all_data(self) -> Dict[str, pd.DataFrame]:
        """Main processing method - orchestrates the entire workflow"""
        try:
            self.logger.info("Starting MOXA Status Feedback processing...")

            # Load dealer data
            df_dealer = self.load_and_process_dealer_data()

            # Process all LOB data
            data_sheets = {}

            for lob in self.config.lobs:
                try:
                    df_lob = self.process_lob_data(lob, df_dealer)
                    data_sheets[lob] = df_lob
                except Exception as e:
                    self.logger.error(f"Failed to process LOB {lob}: {e}")
                    data_sheets[lob] = None

            # Process REFI data
            df_refi = self.process_external_data(
                self.config.file_refi,
                self.refi_column_mapping,
                'REFI'
            )
            if df_refi is not None:
                data_sheets['REFI'] = df_refi

            # Process AMITRA data (currently commented out in original)
            df_amitra = self.process_external_data(
                self.config.file_amitra,
                self.amitra_column_mapping,
                'AMITRA'
            )
            if df_amitra is not None:
                data_sheets['AMITRA'] = df_amitra

            # Validate processed data
            self.validate_processed_data(data_sheets)

            # Export to Excel
            self.export_to_excel(data_sheets)

            self.logger.info("MOXA Status Feedback processing completed successfully!")
            return data_sheets

        except Exception as e:
            self.logger.error(f"Processing failed: {e}")
            raise


def main():
    """Main execution function"""
    try:
        # Initialize processor with default configuration
        processor = MOXAStatusProcessor()

        # Process all data
        results = processor.process_all_data()

        print("Processing completed successfully!")
        print(f"Generated sheets:")
        for sheet_name, df in results.items():
            if df is not None:
                print(f"  - {sheet_name}: {len(df)} records")
            else:
                print(f"  - {sheet_name}: Failed/Skipped")

    except Exception as e:
        print(f"Processing failed: {e}")
        raise


if __name__ == "__main__":
    main()
